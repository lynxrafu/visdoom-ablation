{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ViZDoom Deep RL Ablation Study\n\n**Master's RL Course Final Project**\n\nThis notebook runs the complete ViZDoom ablation study on Google Colab with automatic Drive backup.\n\n## Workflow\n1. **Setup** - Install dependencies, mount Drive\n2. **Quick Test** - Verify environment works (2 min)\n3. **Single Training Test** - Confirm learning works (30 min)\n4. **Ablation Phase 1** - Algorithm comparison: DQN vs Deep SARSA\n5. **Ablation Phase 2** - Learning rate ablation\n6. **Ablation Phase 3** - Extensions: DDQN, Dueling, PER\n7. **Analysis** - Generate report and plots\n\n**Important**: Run phases in separate sessions if needed (Colab ~12h limit)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup\n",
    "\n",
    "Install dependencies and set up virtual display for headless rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running on Colab: {IN_COLAB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies (Colab only)\n",
    "if IN_COLAB:\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -qq -y \\\n",
    "        libboost-all-dev libsdl2-dev libopenal-dev \\\n",
    "        xvfb python3-opengl\n",
    "    print(\"System dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python packages\n",
    "if IN_COLAB:\n",
    "    !pip install -q vizdoom==1.2.4 gymnasium==1.2.3\n",
    "    !pip install -q torch torchvision\n",
    "    !pip install -q wandb hydra-core omegaconf\n",
    "    !pip install -q matplotlib opencv-python numpy\n",
    "    print(\"Python packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up virtual display for headless rendering\n",
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.system('Xvfb :1 -screen 0 1024x768x24 &')\n",
    "    os.environ['DISPLAY'] = ':1'\n",
    "    print(\"Virtual display configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Mount Google Drive and setup directories\nif IN_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    \n    # Create output directory on Drive\n    DRIVE_OUTPUT = '/content/drive/MyDrive/vizdoom-ablation-results'\n    os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n    \n    # Clone repo or use existing\n    REPO_PATH = '/content/vizdoom-ablation'\n    if not os.path.exists(REPO_PATH):\n        !git clone https://github.com/lynxrafu/visdoom-ablation.git {REPO_PATH}\n    \n    %cd {REPO_PATH}\n    \n    # Link results folder to Drive for automatic backup\n    !rm -rf results\n    !ln -s {DRIVE_OUTPUT} results\n    \n    print(f\"Working directory: {os.getcwd()}\")\n    print(f\"Results will be saved to: {DRIVE_OUTPUT}\")\nelse:\n    DRIVE_OUTPUT = 'results'\n    os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n    print(f\"Local mode - results saved to: {DRIVE_OUTPUT}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project to path\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "# Verify imports\n",
    "import torch\n",
    "import gymnasium\n",
    "import vizdoom\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Gymnasium: {gymnasium.__version__}\")\n",
    "print(f\"ViZDoom: {vizdoom.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 2. Quick Test (~2 minutes)\n\nVerify that ViZDoom environment and agent work correctly before long training runs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test environment\n",
    "from src.envs import make_vizdoom_env\n",
    "\n",
    "env = make_vizdoom_env('VizdoomBasic-v0')\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "\n",
    "obs, info = env.reset()\n",
    "print(f\"Initial obs shape: {obs.shape}\")\n",
    "\n",
    "# Take a few random steps\n",
    "for i in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, term, trunc, info = env.step(action)\n",
    "    print(f\"Step {i+1}: action={action}, reward={reward:.2f}\")\n",
    "\n",
    "env.close()\n",
    "print(\"\\nEnvironment test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run quick 10-episode training test\nprint(\"Running quick training test (10 episodes)...\")\n!python experiments/train.py \\\n    training.num_episodes=10 \\\n    logging.wandb_enabled=false \\\n    logging.save_csv=false\n\nprint(\"\\nQuick test passed! Environment and training loop work correctly.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 3. Single Training Test (~30 minutes)\n\nTrain one DQN agent to verify learning happens before running full ablation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nimport os\nos.environ['WANDB_MODE'] = 'disabled'  # Disable WandB (or set to 'online' if you want logging)\n\n# Training parameters for test run\nTEST_EPISODES = 500  # Enough to see learning\nTEST_SCENARIO = 'VizdoomBasic-v0'  # Easiest scenario"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train DQN on Basic scenario\nprint(f\"Training DQN on {TEST_SCENARIO} for {TEST_EPISODES} episodes...\")\nprint(\"This takes ~30 minutes. You should see rewards increasing over time.\\n\")\n\n!python experiments/train.py \\\n    env.scenario={TEST_SCENARIO} \\\n    training.num_episodes={TEST_EPISODES} \\\n    logging.wandb_enabled=false \\\n    seed=42\n\nprint(\"\\nTraining complete! Check the learning curve below.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Find the most recent curve\n",
    "curve_files = glob.glob('results/*_curve.png')\n",
    "if curve_files:\n",
    "    latest = max(curve_files, key=os.path.getctime)\n",
    "    img = Image.open(latest)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No learning curves found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 4. Ablation Study\n\nRun ablation phases one by one. Each phase saves results to Drive automatically.\n\n| Phase | What it tests | Estimated time |\n|-------|--------------|----------------|\n| `algorithms` | DQN vs Deep SARSA | ~1-2 hours |\n| `lr` | Learning rates (0.0001, 0.001, 0.01) | ~1-2 hours |\n| `extensions` | DDQN, Dueling, PER | ~2-3 hours |\n\n**Tip**: If Colab times out, just re-run from where you left off. Results are saved to Drive."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Ablation configuration\nABLATION_EPISODES = 500      # Episodes per run\nABLATION_SEEDS = [1, 2, 3]   # Multiple seeds for statistical significance\nABLATION_SCENARIOS = ['VizdoomBasic-v0']  # Start with Basic, add more later\n\n# Convert to string for command line\nseeds_str = ' '.join(map(str, ABLATION_SEEDS))\nscenarios_str = ' '.join(ABLATION_SCENARIOS)\n\nprint(f\"Ablation settings:\")\nprint(f\"  Episodes: {ABLATION_EPISODES}\")\nprint(f\"  Seeds: {ABLATION_SEEDS}\")\nprint(f\"  Scenarios: {ABLATION_SCENARIOS}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# PHASE 1: Algorithm Comparison (~1-2 hours)\n# Compares: DQN (off-policy) vs Deep SARSA (on-policy)\n# ============================================\nprint(\"=\" * 60)\nprint(\"PHASE 1: Algorithm Comparison (DQN vs Deep SARSA)\")\nprint(\"=\" * 60)\n\n!python experiments/ablate.py \\\n    --phase algorithms \\\n    --scenarios {scenarios_str} \\\n    --seeds {seeds_str} \\\n    --episodes {ABLATION_EPISODES}\n\nprint(\"\\nPhase 1 complete! Results saved to Drive.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# PHASE 2: Learning Rate Ablation (~1-2 hours)\n# Tests: lr = 0.0001, 0.001, 0.01\n# ============================================\nprint(\"=\" * 60)\nprint(\"PHASE 2: Learning Rate Ablation\")\nprint(\"=\" * 60)\n\n!python experiments/ablate.py \\\n    --phase lr \\\n    --scenarios {scenarios_str} \\\n    --seeds {seeds_str} \\\n    --episodes {ABLATION_EPISODES}\n\nprint(\"\\nPhase 2 complete! Results saved to Drive.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# PHASE 3: DQN Extensions (~2-3 hours)\n# Tests: DDQN, Dueling DQN, Prioritized Experience Replay\n# ============================================\nprint(\"=\" * 60)\nprint(\"PHASE 3: DQN Extensions (DDQN, Dueling, PER)\")\nprint(\"=\" * 60)\n\n!python experiments/ablate.py \\\n    --phase extensions \\\n    --scenarios {scenarios_str} \\\n    --seeds {seeds_str} \\\n    --episodes {ABLATION_EPISODES}\n\nprint(\"\\nPhase 3 complete! Results saved to Drive.\")"
  },
  {
   "cell_type": "code",
   "source": "# Check results saved on Drive\nimport glob\nimport os\n\nprint(\"=\" * 60)\nprint(\"RESULTS SAVED TO DRIVE\")\nprint(\"=\" * 60)\n\ncsv_files = sorted(glob.glob('results/*.csv'))\nprint(f\"\\nCSV result files: {len(csv_files)}\")\nfor f in csv_files[-10:]:  # Show last 10\n    size_kb = os.path.getsize(f) / 1024\n    print(f\"  - {os.path.basename(f)} ({size_kb:.1f} KB)\")\n\npng_files = glob.glob('results/*.png')\nprint(f\"\\nLearning curve plots: {len(png_files)}\")\n\nif IN_COLAB:\n    print(f\"\\nAll results backed up to: {DRIVE_OUTPUT}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## 5. Results Analysis\n\nAnalyze all ablation results and generate the IEEE report figures.\n\n**Run this after completing ablation phases** (or after each phase to see intermediate results).",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Use the ResultsAnalyzer for comprehensive analysis\nfrom src.utils.analysis import ResultsAnalyzer, analyze_results\n\n# Initialize analyzer\nanalyzer = ResultsAnalyzer(\"results/\")\nnum_loaded = analyzer.load_all()\nprint(f\"Loaded {num_loaded} experiment results\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display summary table\nif num_loaded > 0:\n    summary_df = analyzer.summary()\n    print(\"Results Summary:\")\n    display(summary_df)\nelse:\n    print(\"No results found. Run ablations first.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare algorithms and print rankings\nif num_loaded > 0:\n    analyzer.compare_algorithms()\n    \n    for scenario in analyzer.get_scenarios():\n        analyzer.print_comparison(scenario)\n        \n        # Get best algorithm\n        best_algo, best_result = analyzer.get_best_algorithm(scenario, \"reward\")\n        print(f\"\\nBest algorithm for {scenario}: {best_algo} (reward: {best_result.reward_mean:.2f})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate complete report with all plots and exports\nif num_loaded > 0:\n    analyzer.generate_report(\n        output_dir=\"results/report\",\n        include_plots=True,\n        include_tables=True\n    )\n    \n    # Display generated files\n    import glob\n    report_files = glob.glob(\"results/report/*\")\n    print(f\"\\nGenerated {len(report_files)} report files:\")\n    for f in report_files:\n        print(f\"  - {f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Export for IEEE Report\n",
    "\n",
    "Export results in formats suitable for the IEEE report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# View generated LaTeX table for IEEE report\nlatex_path = \"results/report/summary.tex\"\nif os.path.exists(latex_path):\n    with open(latex_path, 'r') as f:\n        latex_content = f.read()\n    print(\"LaTeX Table (for IEEE report):\")\n    print(latex_content)\nelse:\n    print(\"No LaTeX table yet. Generate report first.\")\n\n# View JSON report\njson_path = \"results/report/report.json\"\nif os.path.exists(json_path):\n    import json\n    with open(json_path, 'r') as f:\n        report_data = json.load(f)\n    print(\"\\nReport contains:\")\n    print(f\"  - {len(report_data.get('summary', []))} algorithm-scenario combinations\")\n    print(f\"  - {len(report_data.get('comparisons', {}))} scenario comparisons\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n## Notes\n\n### Session Management\n- **Colab free tier**: ~12 hour limit per session\n- **If session times out**: Re-run cells 1-7 (setup), then continue from where you left off\n- **Results are safe**: All outputs saved to Google Drive automatically\n\n### Training Time Estimates\n| Phase | Scenarios | Seeds | Episodes | Time |\n|-------|-----------|-------|----------|------|\n| Quick test | 1 | 1 | 10 | ~2 min |\n| Single training | 1 | 1 | 500 | ~30 min |\n| Algorithm comparison | 1 | 3 | 500 | ~1-2 hours |\n| Learning rate | 1 | 3 | 500 | ~1-2 hours |\n| Extensions | 1 | 3 | 500 | ~2-3 hours |\n\n### For Full Ablation (All Scenarios)\nTo run on all 3 scenarios, update the config cell:\n```python\nABLATION_SCENARIOS = ['VizdoomBasic-v0', 'VizdoomTakeCover-v0', 'VizdoomDeathmatch-v0']\n```\nThis will take significantly longer (~10-15 hours total).\n\n### Tips\n- Use **GPU runtime** for faster training (Runtime > Change runtime type > GPU)\n- Monitor progress via printed episode rewards\n- Check Drive periodically to verify results are saving\n- Run analysis after each phase to see intermediate results"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}