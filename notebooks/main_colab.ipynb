{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ViZDoom Deep RL Ablation Study\n\n**Master's RL Course Final Project**\n\nThis notebook runs the complete ViZDoom ablation study on Google Colab with automatic Drive backup.\n\n## Workflow\n1. **Setup** - Install dependencies, mount Drive\n2. **Quick Test** - Verify environment works (2 min)\n3. **Single Training Test** - Confirm learning works (30 min)\n4. **Ablation Phase 1** - Algorithm comparison: DQN vs Deep SARSA\n5. **Ablation Phase 2** - Learning rate ablation\n6. **Ablation Phase 3** - Extensions: DDQN, Dueling, PER\n7. **Analysis** - Generate report and plots\n\n**Important**: Run phases in separate sessions if needed (Colab ~12h limit)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 1. Environment Setup\n\n**First time?** Run all cells in Section 1.\n\n**Resuming or updating?** Just run the cell below - it handles everything!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# ONE-CLICK SETUP / RESUME / UPDATE\n# ============================================\n# Run this cell to:\n# - Install dependencies (first time)\n# - Pull latest code (if repo updated)\n# - Reconnect to Drive (if session restarted)\n# - Resume from where you left off\n# ============================================\n\nimport sys\nimport os\n\nIN_COLAB = 'google.colab' in sys.modules\nprint(f\"Running on Colab: {IN_COLAB}\")\n\nif IN_COLAB:\n    # 1. Install system dependencies (only if needed)\n    import shutil\n    if not shutil.which('xvfb-run'):\n        print(\"\\n[1/5] Installing system dependencies...\")\n        os.system('apt-get update -qq')\n        os.system('apt-get install -qq -y libboost-all-dev libsdl2-dev libopenal-dev xvfb python3-opengl')\n    else:\n        print(\"\\n[1/5] System dependencies already installed ✓\")\n\n    # 2. Install Python packages (only if needed)\n    try:\n        import vizdoom\n        print(\"[2/5] Python packages already installed ✓\")\n    except ImportError:\n        print(\"[2/5] Installing Python packages...\")\n        os.system('pip install -q vizdoom==1.2.4 gymnasium==1.2.3')\n        os.system('pip install -q torch torchvision')\n        os.system('pip install -q wandb hydra-core omegaconf')\n        os.system('pip install -q matplotlib opencv-python numpy')\n\n    # 3. Setup virtual display\n    os.system('Xvfb :1 -screen 0 1024x768x24 &')\n    os.environ['DISPLAY'] = ':1'\n    print(\"[3/5] Virtual display configured ✓\")\n\n    # 4. Mount Google Drive\n    from google.colab import drive\n    if not os.path.exists('/content/drive/MyDrive'):\n        drive.mount('/content/drive')\n    print(\"[4/5] Google Drive mounted ✓\")\n\n    # 5. Setup repository and results\n    DRIVE_OUTPUT = '/content/drive/MyDrive/vizdoom-ablation-results'\n    REPO_PATH = '/content/vizdoom-ablation'\n    os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n\n    if os.path.exists(REPO_PATH):\n        # Repo exists - pull latest changes\n        print(\"[5/5] Pulling latest code...\")\n        os.system(f'cd {REPO_PATH} && git pull')\n    else:\n        # First time - clone repo\n        print(\"[5/5] Cloning repository...\")\n        os.system(f'git clone https://github.com/lynxrafu/visdoom-ablation.git {REPO_PATH}')\n\n    os.chdir(REPO_PATH)\n\n    # Link results to Drive (recreate symlink)\n    if os.path.exists('results') and not os.path.islink('results'):\n        os.system('rm -rf results')\n    if not os.path.exists('results'):\n        os.symlink(DRIVE_OUTPUT, 'results')\n\n    print(f\"\\n{'='*50}\")\n    print(f\"✓ Ready! Working directory: {os.getcwd()}\")\n    print(f\"✓ Results saved to: {DRIVE_OUTPUT}\")\n\n    # Show existing results\n    from pathlib import Path\n    runs = list(Path(DRIVE_OUTPUT).glob(\"**/metadata.json\"))\n    print(f\"✓ Existing runs found: {len(runs)}\")\n    print(f\"{'='*50}\")\n\nelse:\n    DRIVE_OUTPUT = 'results'\n    os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n    print(f\"Local mode - results saved to: {DRIVE_OUTPUT}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Skip this cell - handled by ONE-CLICK SETUP above"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Skip this cell - handled by ONE-CLICK SETUP above"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 2. Quick Test (~2 minutes)\n\nVerify that ViZDoom environment and agent work correctly before long training runs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run quick 10-episode training test (WandB disabled for speed)\nprint(\"Running quick training test (10 episodes)...\")\n!python experiments/train.py \\\n    training.num_episodes=10 \\\n    logging.wandb_enabled=false \\\n    logging.csv_log=false\n\nprint(\"\\nQuick test passed! Environment and training loop work correctly.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 3. Configuration (Edit This Cell Only!)\n\n**All training settings in ONE place.** Change values here, then run any training cell."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# CONFIGURATION - EDIT HERE ONLY!\n# ============================================\n# All training settings in one place.\n# Change these values, then run any training/ablation cell.\n\n# --- Training Duration ---\nEPISODES = 500              # Episodes per training run (500=test, 2000=full)\n\n# --- Scenarios to Test ---\nSCENARIOS = [\n    'VizdoomBasic-v0',      # Easy - basic shooting (recommended to start)\n    # 'VizdoomTakeCover-v0',  # Medium - dodge fireballs\n    # 'VizdoomDeathmatch-v0', # Hard - full combat\n]\n\n# --- Seeds for Statistical Significance ---\nSEEDS = [1, 2, 3]           # Multiple seeds for reliable results\n\n# --- Display Summary ---\nprint(\"=\" * 50)\nprint(\"CURRENT CONFIGURATION\")\nprint(\"=\" * 50)\nprint(f\"Episodes per run:  {EPISODES}\")\nprint(f\"Scenarios:         {SCENARIOS}\")\nprint(f\"Seeds:             {SEEDS}\")\nprint(f\"Total runs needed: {len(SCENARIOS) * len(SEEDS)} per phase\")\nprint(\"=\" * 50)\nprint(\"\\nEdit this cell to change settings, then run training cells.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Single DQN Training Run (uses config from cell above)\nscenario = SCENARIOS[0]  # First scenario from config\nseed = SEEDS[0]          # First seed from config\n\nprint(f\"Training DQN on {scenario} for {EPISODES} episodes (seed={seed})...\")\nprint(\"Track progress at: https://wandb.ai/\\n\")\n\n!python experiments/train.py \\\n    env.scenario={scenario} \\\n    training.num_episodes={EPISODES} \\\n    seed={seed}\n\nprint(\"\\nTraining complete! Check WandB dashboard for detailed metrics.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Find the most recent curve\n",
    "curve_files = glob.glob('results/*_curve.png')\n",
    "if curve_files:\n",
    "    latest = max(curve_files, key=os.path.getctime)\n",
    "    img = Image.open(latest)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No learning curves found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 4. Ablation Study\n\nRun ablation phases using the configuration from Section 3.\n\n| Phase | What it tests | Runs per scenario |\n|-------|--------------|-------------------|\n| `algorithms` | DQN vs Deep SARSA | 2 × seeds |\n| `lr` | Learning rates (0.0001, 0.001, 0.01) | 3 × seeds |\n| `extensions` | DDQN, Dueling, PER | 4 × seeds |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare command line arguments from configuration (Section 3)\nseeds_str = ' '.join(map(str, SEEDS))\nscenarios_str = ' '.join(SCENARIOS)\n\nprint(f\"Using configuration from Section 3:\")\nprint(f\"  Episodes:  {EPISODES}\")\nprint(f\"  Scenarios: {scenarios_str}\")\nprint(f\"  Seeds:     {seeds_str}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# PHASE 1: Algorithm Comparison\n# Compares: DQN (off-policy) vs Deep SARSA (on-policy)\n# ============================================\nprint(\"=\" * 60)\nprint(\"PHASE 1: Algorithm Comparison (DQN vs Deep SARSA)\")\nprint(f\"Episodes: {EPISODES} | Scenarios: {len(SCENARIOS)} | Seeds: {len(SEEDS)}\")\nprint(\"Track progress at: https://wandb.ai/\")\nprint(\"=\" * 60)\n\n!python experiments/ablate.py \\\n    --phase algorithms \\\n    --scenarios {scenarios_str} \\\n    --seeds {seeds_str} \\\n    --episodes {EPISODES}\n\nprint(\"\\nPhase 1 complete! Results saved to Drive and WandB.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# PHASE 2: Learning Rate Ablation\n# Tests: lr = 0.0001, 0.001, 0.01\n# ============================================\nprint(\"=\" * 60)\nprint(\"PHASE 2: Learning Rate Ablation\")\nprint(f\"Episodes: {EPISODES} | Scenarios: {len(SCENARIOS)} | Seeds: {len(SEEDS)}\")\nprint(\"Track progress at: https://wandb.ai/\")\nprint(\"=\" * 60)\n\n!python experiments/ablate.py \\\n    --phase lr \\\n    --scenarios {scenarios_str} \\\n    --seeds {seeds_str} \\\n    --episodes {EPISODES}\n\nprint(\"\\nPhase 2 complete! Results saved to Drive and WandB.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# PHASE 3: DQN Extensions\n# Tests: DDQN, Dueling DQN, Prioritized Experience Replay\n# ============================================\nprint(\"=\" * 60)\nprint(\"PHASE 3: DQN Extensions (DDQN, Dueling, PER)\")\nprint(f\"Episodes: {EPISODES} | Scenarios: {len(SCENARIOS)} | Seeds: {len(SEEDS)}\")\nprint(\"Track progress at: https://wandb.ai/\")\nprint(\"=\" * 60)\n\n!python experiments/ablate.py \\\n    --phase extensions \\\n    --scenarios {scenarios_str} \\\n    --seeds {seeds_str} \\\n    --episodes {EPISODES}\n\nprint(\"\\nPhase 3 complete! Results saved to Drive and WandB.\")"
  },
  {
   "cell_type": "code",
   "source": "# Check results saved on Drive - New organized structure\nimport glob\nimport os\nfrom pathlib import Path\n\nprint(\"=\" * 60)\nprint(\"RESULTS SAVED TO DRIVE\")\nprint(\"=\" * 60)\n\nresults_path = Path('results')\nif results_path.exists():\n    # Find all run directories (contain metadata.json)\n    run_dirs = list(results_path.glob(\"**/metadata.json\"))\n    print(f\"\\nTotal training runs: {len(run_dirs)}\")\n\n    # Show recent runs\n    print(\"\\nRecent runs:\")\n    for meta_path in sorted(run_dirs, key=lambda x: x.stat().st_mtime, reverse=True)[:5]:\n        run_dir = meta_path.parent\n        import json\n        with open(meta_path) as f:\n            meta = json.load(f)\n        print(f\"  - {run_dir.relative_to(results_path)}\")\n        print(f\"    Agent: {meta.get('agent_type')} | Scenario: {meta.get('scenario')} | Seed: {meta.get('seed')}\")\n\n    if IN_COLAB:\n        print(f\"\\nAll results backed up to: {DRIVE_OUTPUT}\")\nelse:\n    print(\"No results yet. Run training first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## 5. Results Analysis\n\nAnalyze all ablation results and generate the IEEE report figures.\n\n**Run this after completing ablation phases** (or after each phase to see intermediate results).",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Use the ResultsAnalyzer for comprehensive analysis\nfrom src.utils.analysis import ResultsAnalyzer, analyze_results\n\n# Initialize analyzer\nanalyzer = ResultsAnalyzer(\"results/\")\nnum_loaded = analyzer.load_all()\nprint(f\"Loaded {num_loaded} experiment results\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display summary table\nif num_loaded > 0:\n    summary_df = analyzer.summary()\n    print(\"Results Summary:\")\n    display(summary_df)\nelse:\n    print(\"No results found. Run ablations first.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare algorithms and print rankings\nif num_loaded > 0:\n    analyzer.compare_algorithms()\n    \n    for scenario in analyzer.get_scenarios():\n        analyzer.print_comparison(scenario)\n        \n        # Get best algorithm\n        best_algo, best_result = analyzer.get_best_algorithm(scenario, \"reward\")\n        print(f\"\\nBest algorithm for {scenario}: {best_algo} (reward: {best_result.reward_mean:.2f})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate complete report with all plots and exports\nif num_loaded > 0:\n    analyzer.generate_report(\n        output_dir=\"results/report\",\n        include_plots=True,\n        include_tables=True\n    )\n    \n    # Display generated files\n    import glob\n    report_files = glob.glob(\"results/report/*\")\n    print(f\"\\nGenerated {len(report_files)} report files:\")\n    for f in report_files:\n        print(f\"  - {f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Export for IEEE Report\n",
    "\n",
    "Export results in formats suitable for the IEEE report."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n## Quick Reference\n\n### Your Workflow\n\n| Situation | What to do |\n|-----------|------------|\n| **First time** | Run cell 2 (ONE-CLICK SETUP) → Run cell 7 (verify imports) → Continue |\n| **Session timeout** | Run cell 2 (ONE-CLICK SETUP) → Continue where you left off |\n| **Repo updated** | Run cell 2 (ONE-CLICK SETUP) - it auto-pulls changes |\n| **Check progress** | Run Section 5 (Analysis) anytime |\n\n### Session Management\n- **ONE-CLICK SETUP (cell 2)** handles everything: install, mount, pull, resume\n- **Results are on Drive** - never lost even if session dies\n- **Just run cell 2** whenever you start/resume - it's smart enough to skip what's already done\n\n### Training Time Estimates\n| Phase | Scenarios | Seeds | Episodes | Time |\n|-------|-----------|-------|----------|------|\n| Quick test | 1 | 1 | 10 | ~2 min |\n| Single training | 1 | 1 | 500 | ~30 min |\n| Algorithm comparison | 1 | 3 | 500 | ~1-2 hours |\n| Learning rate ablation | 1 | 3 | 500 | ~1-2 hours |\n| Extensions ablation | 1 | 3 | 500 | ~2-3 hours |\n\n### Output Structure\n```\nGoogle Drive/vizdoom-ablation-results/\n└── 2025-12-25/\n    └── 143052_dqn_VizdoomBasic_v0_lr0.0001_seed42/\n        ├── metadata.json      # What was run\n        ├── config.yaml        # Full config\n        ├── training_log.csv   # All metrics\n        ├── summary.json       # Final results\n        ├── checkpoints/       # Model weights\n        └── plots/             # Learning curves\n```\n\n### Tips\n- Use **GPU runtime** for faster training\n- Run **cell 2 first** every time you open the notebook\n- Check **Section 5 (Analysis)** to see all your runs\n- Each run gets a **unique timestamp** - nothing is ever overwritten"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}